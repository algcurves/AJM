{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/algcurves/AJM/blob/master/Shaska_Linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OW_JQtGQ1N4"
      },
      "source": [
        "# Linear regression\n",
        "Suppose there are $m$ data points, each with $n$ predictors (known features) and $t$ targets (unknown features in the test set).\n",
        "\n",
        "Store the predictors in the matrix $X$, which is an $m \\times n$ matrix, with each row corresponding to one data point.\n",
        "\n",
        "Store the targets in the matrix $Y$, which is an $m \\times t$ matrix, corresponding to $X$ (i.e., the rows of $X$ and $Y$ are one-to-one mapped).\n",
        "\n",
        "In the lecture, we only consider a single target variable. Here $Y$ consists of $t$ target variables. The closed form solution is the same as we had derived in this [video](https://oakland.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=01a9d556-4e95-4079-b028-ad980025411a).\n",
        "\n",
        "Mathematically, linear regression solves this optimization problem:\n",
        "\n",
        "Given $X$ and $Y$, find the best $W$ and $b$ such that\n",
        "\n",
        "$$Y \\approx XW + b$$\n",
        "\n",
        "Linear regression then solves this optimization problem:\n",
        "\n",
        "$$W^*, b^* = \\underset{W, b}{\\operatorname{argmin}} ||Y - (XW + b)||^{2}$$\n",
        "\n",
        "Here, $W$ is a $n \\times t$ weight matrix, $b$ is a bias vector of length $t$.\n",
        "\n",
        "Now let's use a trick to absort $b$ into $W$.\n",
        "\n",
        "Let $X_{extend}=[X, \\bf{1}]$, i.e., append a column of 1 to the last column of $X$. Here $\\bf{1}$$=[1,1,\\cdots,1]^T$ is  a column vector of length $m$ with every element being 1.\n",
        "\n",
        "\n",
        "\\begin{equation*}\n",
        "W_{extend} =\n",
        "\\begin{bmatrix}\n",
        "W \\\\\n",
        "b\n",
        "\\end{bmatrix}\n",
        "\\end{equation*}\n",
        "\n",
        "Now $W^*_{extend}$ is a $(n+1) \\times t$ matrix, with the first $n$ row corresponding to $W^*$ and the last row $b^*$.\n",
        "\n",
        "For your information, the closed form solution with linear regression is\n",
        "\n",
        "$$W^*_{extend}=(X^{T}_{extend}X_{extend})^{-1}X^{T}_{extend}Y$$\n",
        "\n",
        "You can then read out $W^*, b^*$ directly from $W^*_{extend}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkxjOLWwQ1N7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcLkwHmJQ1N7"
      },
      "source": [
        "def linear_regression_params(X, Y):\n",
        "    \"\"\"Given a set of data points stored in X and Y, find the best weight matrix and bias\n",
        "\n",
        "    Arguments:\n",
        "        X: 2D numpy array with shape (num_points, num_features)\n",
        "        Y: 2D numpy array with shape (num_points, num_targets)\n",
        "\n",
        "    Returns:\n",
        "        W: 2D numpy array with shape (num_features, num_targets)\n",
        "        b: b is a 1D numpy array with shape (num_targets,)\n",
        "    \"\"\"\n",
        "    W = None\n",
        "    b = None\n",
        "    ################################################################################\n",
        "    ######################### Write your code in this block (20 points) ############\n",
        "    ## 20 points ##\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "\n",
        "    X0 = np.ones((len(X),1))\n",
        "    XX = np.hstack((X,X0))\n",
        "\n",
        "    A=np.matmul(XX.transpose(), XX )\n",
        "\n",
        "    B=np.linalg.inv(np.matrix(A))\n",
        "    WW=np.matmul(np.matmul(B,  XX.transpose() ), Y)\n",
        "\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    return WW\n",
        "\n",
        "\n",
        "def linear_regression_predict(W, b, X_test):\n",
        "    \"\"\"Given weight matrix W and bias vector b (b can be None), predict the target matrix for X_test\n",
        "\n",
        "    Arguments:\n",
        "        W: 2D numpy array with shape (num_features, num_targets)\n",
        "        b: b can be a 1D numpy array with shape (num_targets,) or b is None\n",
        "        X_test: 2D numpy array with shape (num_points, num_features)\n",
        "\n",
        "    Returns:\n",
        "        Y_test: 2D numpy array with shape (num_points, num_targets)\n",
        "\n",
        "    \"\"\"\n",
        "    Y_test = None\n",
        "    ################################################################################\n",
        "    ######################### Write your code in this block (5 points) #############\n",
        "    ## 5 points ##\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    return Y_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=[[21,2,3],[3,4,5]]\n",
        "Y=[[31,2],[3,4]]\n",
        "linear_regression_params(X, Y)"
      ],
      "metadata": {
        "id": "hzjfH-GrrmsO",
        "outputId": "c70e4895-efee-4feb-ac86-2a9ad634bb4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[ 2.46875,  0.21875],\n",
              "        [-8.125  , -1.     ],\n",
              "        [-0.5    ,  0.5625 ],\n",
              "        [15.5    ,  1.     ]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF70w4ILQ1N8"
      },
      "source": [
        "# Evaluate your implementation\n",
        "After you have implemented the above two functions: linear_regression_params and linear_regression_predict\n",
        "Use the following code to evaluate your implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpanCDKLQ1N8"
      },
      "source": [
        "def generate_evaluation_data(num_features, num_targets, noise_level=1):\n",
        "    w_true = np.random.uniform(-5, 5, (num_features, num_targets))\n",
        "    b_true = np.random.uniform(-10, 10, (num_targets,))\n",
        "\n",
        "    x_train = np.random.uniform(1, 10, (100, num_features))\n",
        "    y_train = x_train.dot(w_true) + b_true\n",
        "    noise = np.random.randn(*y_train.shape) * noise_level\n",
        "    y_train += noise\n",
        "\n",
        "    x_test = np.random.uniform(1, 10, (200, num_features))\n",
        "    y_test = x_test.dot(w_true) + b_true\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test), (w_true, b_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkOjMQtUQ1N9",
        "outputId": "8d946103-d2cc-425b-cd0e-e286bb94fd8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "noise_level = 0.01\n",
        "for i, (num_features, num_targets) in enumerate([(1, 1), (10, 1), (10, 10)]):\n",
        "    print(f'num_features = {num_features}, num_targets = {num_targets}')\n",
        "    # generate evaluation dataset\n",
        "    (x_train, y_train), (x_test, y_test), (w_true, b_true) = generate_evaluation_data(num_features, num_targets, noise_level)\n",
        "\n",
        "    # Use x_train and y_train as training data to fit your model;\n",
        "    # then calculate the prediction y_pred for x_test\n",
        "    w, b = linear_regression_params(x_train, y_train)\n",
        "    y_pred = linear_regression_predict(w, b, x_test)\n",
        "\n",
        "    # visualize the results\n",
        "    i = np.random.choice(num_features) # if there are multiple predictors (features), randomly select one to plot as x\n",
        "    j = np.random.choice(num_targets) # if there are multiple targets\n",
        "    plt.plot(x_train[:, i], y_train[:, j], 'r+', label='train', alpha=0.5)\n",
        "    plt.plot(x_test[:, i], y_test[:, j], 'b*', label='test', alpha=0.5)\n",
        "    plt.plot(x_test[:, i], y_pred[:, j], 'gv', label='pred', alpha=0.5)\n",
        "    plt.xlabel(f'x_{i}')\n",
        "    plt.ylabel(f'y_{j}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    # print result summary\n",
        "    print(f'True parameters: w_true={w_true}, b_true={b_true}')\n",
        "    print(f'Learned parameters: w={w}, b={b}')\n",
        "    print(f'The distance between w_true and w: {np.linalg.norm(w_true - w)}')\n",
        "    print(f'The distance between b_true and b: {np.linalg.norm(b_true - b)}')\n",
        "    print(f'The distance between y_pred and y_test: {np.linalg.norm(y_test - y_pred)}\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_features = 1, num_targets = 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b55cf5a37287>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'num_features = {num_features}, num_targets = {num_targets}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# generate evaluation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_evaluation_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Use x_train and y_train as training data to fit your model;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-0f23a0084d35>\u001b[0m in \u001b[0;36mgenerate_evaluation_data\u001b[0;34m(num_features, num_targets, noise_level)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_evaluation_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mw_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mb_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    }
  ]
}